{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edward/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data_augmentation import random_transform\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import applications\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Reshape, Flatten, Input, merge, subtract, Lambda, Dropout\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resize_shape = (256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# Take this out later\n",
    "data = data.head(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data = shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For now, we remove new_whale\n",
    "# data = data[data['Id'] != 'new_whale'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open('data/train/00022e1a.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 699)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 699)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_image = np.stack([image]*3,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 699, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(new_image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gray = np.mean(image, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.imshow(random_transform(gray),cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# All images (if small) can be held in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list = data['Image']\n",
    "id_list = data['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image(file, shape=(resize_shape[0],resize_shape[1])):\n",
    "    image = Image.open('data/train/' + file)\n",
    "    image = image.resize(shape)\n",
    "    image = np.array(image)\n",
    "    if len(image.shape) == 2:\n",
    "        image = np.stack([image]*3,axis=2) \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_list = [get_image(f) for f in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length_list = [len(image.shape) for image in image_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00022e1a.jpg'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['image_array'] = image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "      <th>image_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>05859f6e.jpg</td>\n",
       "      <td>w_5a29f9d</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0c09bf79.jpg</td>\n",
       "      <td>w_849b126</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>06256148.jpg</td>\n",
       "      <td>w_53859b2</td>\n",
       "      <td>[[[93, 107, 152], [93, 107, 152], [93, 108, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>07c2def7.jpg</td>\n",
       "      <td>w_b8f8e69</td>\n",
       "      <td>[[[197, 197, 197], [204, 204, 204], [198, 198,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Image         Id  \\\n",
       "233  05859f6e.jpg  w_5a29f9d   \n",
       "486  0c09bf79.jpg  w_849b126   \n",
       "260  06256148.jpg  w_53859b2   \n",
       "330  07c2def7.jpg  w_b8f8e69   \n",
       "\n",
       "                                           image_array  \n",
       "233  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "486  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "260  [[[93, 107, 152], [93, 107, 152], [93, 108, 14...  \n",
       "330  [[[197, 197, 197], [204, 204, 204], [198, 198,...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_proportion = 0.8\n",
    "cutoff_index = int(len(data) * test_proportion)\n",
    "\n",
    "training_data = data.iloc[:cutoff_index].reset_index(drop=True)\n",
    "test_data = data.iloc[cutoff_index:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "training_counts = Counter(training_data['Id'])\n",
    "training_data['Id_count'] = training_data.apply(lambda x: training_counts.get(x[\"Id\"]), axis=1)\n",
    "\n",
    "test_counts = Counter(test_data['Id'])\n",
    "test_data['Id_count'] = test_data.apply(lambda x: test_counts.get(x[\"Id\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_triple(len_data, data_images, data_ids, anchor_condition, augment=True):\n",
    "    \n",
    "    anchor_index = np.random.choice(anchor_condition.index[anchor_condition])    \n",
    "    anchor_image = data_images[anchor_index]\n",
    "    anchor_id = data_ids[anchor_index]   \n",
    "\n",
    "    same_id = anchor_id    \n",
    "    same_id_indices = (data_ids == anchor_id)\n",
    "    same_id_index = np.random.choice(same_id_indices.index[same_id_indices])\n",
    "    same_image = data_images[same_id_index]\n",
    "    \n",
    "    different_id = anchor_id\n",
    "    \n",
    "    while (anchor_id == different_id):\n",
    "        different_index = randint(0,len_data-1)\n",
    "        different_id = data_ids[different_index]\n",
    "    \n",
    "    different_image = data_images[different_index]\n",
    "    \n",
    "    if augment:\n",
    "        anchor_image = random_transform(anchor_image)\n",
    "        same_image = random_transform(same_image)\n",
    "        different_image = random_transform(different_image)\n",
    "    return anchor_image, same_image, different_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def triple_generator(batch_size, data, resize_shape, augment=True):\n",
    "    \n",
    "    len_data = len(data)\n",
    "    data_images = np.stack(data['image_array'])\n",
    "    data_ids = data['Id']\n",
    "    \n",
    "    anchor_condition = (data['Id_count'] > 1) & (data_ids != 'new_whale')\n",
    "        \n",
    "    \n",
    "    while True:\n",
    "        anchor_batch = np.zeros((batch_size, resize_shape[0],resize_shape[1],resize_shape[2]))\n",
    "        same_image_batch = np.zeros((batch_size, resize_shape[0],resize_shape[1],resize_shape[2]))\n",
    "        different_image_batch = np.zeros((batch_size, resize_shape[0],resize_shape[1],resize_shape[2]))\n",
    "        for i in range(batch_size):\n",
    "#             print(\"assigning next images...\")\n",
    "            anchor_batch[i,:,:,:], same_image_batch[i,:,:,:], different_image_batch[i,:,:,:] = get_triple(\n",
    "                    len_data, data_images, data_ids, anchor_condition, augment)\n",
    "\n",
    "        batches = [anchor_batch, same_image_batch, different_image_batch]\n",
    "        yield batches, np.ones(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training_data_generator = triple_generator(16, training_data, resize_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len_data = len(training_data)\n",
    "# data_images = np.stack(training_data['image_array'])\n",
    "# data_ids = training_data['Id']\n",
    "# anchor_condition = (training_data['Id_count'] > 1) & (data_ids != 'new_whale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get_triple(len_data, data_images, data_ids, anchor_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# next(training_data_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = resize_shape\n",
    "\n",
    "anchor_input = Input(input_shape)\n",
    "same_category_input = Input(input_shape)\n",
    "different_category_input = Input(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edward/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:58: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/edward/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:464: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/edward/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"lo...)`\n"
     ]
    }
   ],
   "source": [
    "def bpr_triplet_loss(X):    \n",
    "    margin = 3\n",
    "    \n",
    "    anchor_embedding, same_embedding, different_embedding = X\n",
    "    \n",
    "    positive_distance = K.square(anchor_embedding - same_embedding)\n",
    "    negative_distance = K.square(anchor_embedding - different_embedding)\n",
    "    \n",
    "    positive_distance = K.mean(positive_distance, axis=-1, keepdims=True)\n",
    "    negative_distance = K.mean(negative_distance, axis=-1, keepdims=True)\n",
    "    \n",
    "    loss = K.maximum(0.0, margin + positive_distance - negative_distance)\n",
    "   \n",
    "    return K.mean(loss)\n",
    "\n",
    "def triplet_loss(inputs, dist='sqeuclidean', margin='maxplus', alpha=0.1):\n",
    "    anchor, positive, negative = inputs\n",
    "    positive_distance = K.square(anchor - positive)\n",
    "    negative_distance = K.square(anchor - negative)\n",
    "    if dist == 'euclidean':\n",
    "        positive_distance = K.sqrt(K.sum(positive_distance, axis=-1, keepdims=True))\n",
    "        negative_distance = K.sqrt(K.sum(negative_distance, axis=-1, keepdims=True))\n",
    "    elif dist == 'sqeuclidean':\n",
    "        positive_distance = K.mean(positive_distance, axis=-1, keepdims=True)\n",
    "        negative_distance = K.mean(negative_distance, axis=-1, keepdims=True)\n",
    "    loss = positive_distance - negative_distance\n",
    "    if margin == 'maxplus':\n",
    "        loss = K.maximum(0.0, alpha + loss)\n",
    "    elif margin == 'softplus':\n",
    "        loss = K.log(alpha + K.exp(loss))\n",
    "    return K.mean(loss)    \n",
    "    \n",
    "convnet = Sequential()\n",
    "convnet.add(Conv2D(filters=8, input_shape=(\n",
    "    resize_shape[0],resize_shape[1],resize_shape[2],), kernel_size=5, activation='relu',name='conv_1'))\n",
    "convnet.add(MaxPooling2D(pool_size=2,name='pool_1'))\n",
    "convnet.add(Conv2D(filters=12, kernel_size=3, activation='relu',name='conv_2'))\n",
    "convnet.add(MaxPooling2D(pool_size=2,name='pool_2'))\n",
    "convnet.add(Conv2D(filters=16, kernel_size=3, activation='relu',name='conv_3'))\n",
    "convnet.add(MaxPooling2D(pool_size=2,name='pool_3'))\n",
    "convnet.add(Conv2D(filters=20, kernel_size=3, activation='relu',name='conv_4'))\n",
    "convnet.add(Conv2D(filters=32, kernel_size=3, activation='relu',name='conv_5'))\n",
    "convnet.add(MaxPooling2D(pool_size=2,name='pool_4'))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(units=128, activation='relu',name='dense_1'))\n",
    "convnet.add(Dense(units=64, activation='relu',name='dense_2'))\n",
    "# convnet.add(Dense(units=64, activation='linear',name='dense_3'))\n",
    "# convnet.add(Lambda(lambda x: K.l2_normalize(x,axis=1), name='normalize'))\n",
    "\n",
    "anchor = convnet(anchor_input)\n",
    "same = convnet(same_category_input)\n",
    "different = convnet(different_category_input)\n",
    "\n",
    "loss = merge(\n",
    "        [anchor, same, different],\n",
    "        mode=bpr_triplet_loss,\n",
    "        name='loss',\n",
    "        output_shape=(1, ))\n",
    "    \n",
    "siamese_net = Model(input=[anchor_input,same_category_input, different_category_input],output=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity_loss(y_true, y_pred):\n",
    "    return K.mean(y_pred - 0 * y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LEARNING_RATE = 0.1\n",
    "# siamese_net.compile(loss=identity_loss,optimizer=SGD(LEARNING_RATE))\n",
    "siamese_net.compile(loss=identity_loss,optimizer=Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "training_data_generator = triple_generator(BATCH_SIZE, training_data, resize_shape, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edward/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:2095: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 0.6288\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 34s 339ms/step - loss: 0.2717\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 34s 343ms/step - loss: 0.1171\n"
     ]
    }
   ],
   "source": [
    "history = siamese_net.fit_generator(training_data_generator,\n",
    "                                    verbose=1, \n",
    "                                    epochs=3, \n",
    "                                    steps_per_epoch=100,\n",
    "                                    workers=4,\n",
    "                                    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEWCAYAAACdaNcBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febcc3f9978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title(\"Loss function\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric names ['loss']\n",
      "Metric values 1.3475242584943772\n"
     ]
    }
   ],
   "source": [
    "evaluation_data_generator = triple_generator(BATCH_SIZE, test_data, resize_shape, augment=False)\n",
    "evaluation_steps = 20\n",
    "metric_names = siamese_net.metrics_names\n",
    "metric_values = siamese_net.evaluate_generator(evaluation_data_generator, steps=evaluation_steps)\n",
    "print(\"Metric names\", metric_names)\n",
    "print(\"Metric values\", metric_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "now = time.strftime('%Y.%m.%d %H:%M:%S')\n",
    "weights_directory = \"weights/\" + now + \"/\"\n",
    "if not os.path.exists(weights_directory):\n",
    "    os.makedirs(weights_directory)\n",
    "\n",
    "\n",
    "siamese_net.save_weights(weights_directory + \"siamese_weights\")\n",
    "convnet.save_weights(weights_directory + \"convnet_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"data/train.csv\")\n",
    "# file_list = data['Image']\n",
    "# image_list = [get_image(f) for f in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# id_list = data['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Will want to change this to say trained embedding list. Or trained embeddings.\n",
    "\n",
    "embedding_list = convnet.predict(np.stack(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_image(file, shape=(resize_shape[0],resize_shape[1])):\n",
    "    image = Image.open('data/test/' + file)\n",
    "    image = image.resize(shape)\n",
    "    image = np.array(image)\n",
    "    if len(image.shape) == 2:\n",
    "        image = np.stack([image]*3,axis=2) \n",
    "    return image\n",
    "\n",
    "\n",
    "sample_sub = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "\n",
    "#Comment out:\n",
    "sample_sub = sample_sub.head(200)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "submission_file_list = sample_sub['Image']\n",
    "submission_image_list = [get_sub_image(f) for f in submission_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_embedding_list = convnet.predict(np.stack(submission_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(li):\n",
    "    my_set = set()\n",
    "    filtered = []\n",
    "    for e in li:\n",
    "        if e not in my_set:\n",
    "            filtered.append(e)\n",
    "            my_set.add(e)\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def classify(image_embedding, embedding_list, id_list, num_categories=5):\n",
    "    image_embedding = np.expand_dims(image_embedding, axis=0)\n",
    "    stacked_image = np.repeat(image_embedding,len(embedding_list),axis=0)\n",
    "    square_differences = (stacked_image - embedding_list)**2\n",
    "    scores = np.sum(square_differences, axis=1)\n",
    "    \n",
    "    #Take out magic 3. Put in margin.\n",
    "    \n",
    "    scores = np.append(scores, [3], axis=0)\n",
    "    id_list = np.append(id_list, ['new_whale'], axis=0)\n",
    "    \n",
    "    sorted_ids = [x for (y,x) in sorted(\n",
    "        zip(scores,id_list), key=lambda pair: pair[0])]\n",
    "    \n",
    "    return ' '.join(remove_duplicates(sorted_ids)[0:num_categories])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new_whale w_44f66a7 w_b59c523 w_290f82b w_dbda0d6'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(submission_embedding_list[7], embedding_list, id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "      <th>image_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>05859f6e.jpg</td>\n",
       "      <td>w_5a29f9d</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0c09bf79.jpg</td>\n",
       "      <td>w_849b126</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>06256148.jpg</td>\n",
       "      <td>w_53859b2</td>\n",
       "      <td>[[[93, 107, 152], [93, 107, 152], [93, 108, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>07c2def7.jpg</td>\n",
       "      <td>w_b8f8e69</td>\n",
       "      <td>[[[197, 197, 197], [204, 204, 204], [198, 198,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>019cd867.jpg</td>\n",
       "      <td>w_0ead9d7</td>\n",
       "      <td>[[[32, 32, 32], [32, 32, 32], [36, 36, 36], [3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>04dd6cc6.jpg</td>\n",
       "      <td>w_3197568</td>\n",
       "      <td>[[[252, 252, 252], [252, 252, 252], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>02916b71.jpg</td>\n",
       "      <td>w_73d5489</td>\n",
       "      <td>[[[55, 85, 109], [49, 79, 103], [59, 89, 113],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>02715625.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "      <td>[[[131, 131, 131], [131, 131, 131], [131, 131,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0026a8ab.jpg</td>\n",
       "      <td>w_eaad6a8</td>\n",
       "      <td>[[[204, 204, 204], [204, 204, 204], [204, 204,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>03f8cf5a.jpg</td>\n",
       "      <td>w_b8f8e69</td>\n",
       "      <td>[[[216, 216, 216], [216, 216, 216], [216, 216,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Image         Id  \\\n",
       "233  05859f6e.jpg  w_5a29f9d   \n",
       "486  0c09bf79.jpg  w_849b126   \n",
       "260  06256148.jpg  w_53859b2   \n",
       "330  07c2def7.jpg  w_b8f8e69   \n",
       "63   019cd867.jpg  w_0ead9d7   \n",
       "201  04dd6cc6.jpg  w_3197568   \n",
       "104  02916b71.jpg  w_73d5489   \n",
       "102  02715625.jpg  new_whale   \n",
       "6    0026a8ab.jpg  w_eaad6a8   \n",
       "155  03f8cf5a.jpg  w_b8f8e69   \n",
       "\n",
       "                                           image_array  \n",
       "233  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "486  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "260  [[[93, 107, 152], [93, 107, 152], [93, 108, 14...  \n",
       "330  [[[197, 197, 197], [204, 204, 204], [198, 198,...  \n",
       "63   [[[32, 32, 32], [32, 32, 32], [36, 36, 36], [3...  \n",
       "201  [[[252, 252, 252], [252, 252, 252], [255, 255,...  \n",
       "104  [[[55, 85, 109], [49, 79, 103], [59, 89, 113],...  \n",
       "102  [[[131, 131, 131], [131, 131, 131], [131, 131,...  \n",
       "6    [[[204, 204, 204], [204, 204, 204], [204, 204,...  \n",
       "155  [[[216, 216, 216], [216, 216, 216], [216, 216,...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_embedding_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_embedding_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_prediction_list = [classify(image_embedding, embedding_list, id_list) for image_embedding in submission_embedding_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Image': submission_file_list, 'Id': submission_prediction_list}, columns=['Image','Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_directory = \"results/\" + now + \"/\"\n",
    "if not os.path.exists(results_directory):\n",
    "    os.makedirs(results_directory)\n",
    "    \n",
    "submission.to_csv(results_directory + \"submission.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
