{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data_augmentation import random_transform\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Reshape, Flatten, Input, merge\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For now, we remove new_whale\n",
    "data = data[data['Id'] != 'new_whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9040"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open('data/train/0a5c0f48.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = image.resize((256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(image).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's probably good to resize these images to (256, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its not sensible to read all the images into memory. So, we will read them in in batches of arbitrary size BATCH_SIZE (8?), and fit to them. Then do the same when predicting. Maybe use model.fit_generator? Generator can load files, preprocess and yield them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gray = np.mean(image, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(gray,cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a map from a list of filenames and labels to an X, y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(image, size=(256,256)):\n",
    "    image = image.resize(size)  \n",
    "    image = np.array(image)\n",
    "    if len(image.shape) == 3:\n",
    "        image = np.mean(image, -1) \n",
    "    assert image.shape == (256,256)\n",
    "    return image\n",
    "\n",
    "def file_to_image(filename):\n",
    "    raw_image = Image.open('data/train/' + filename)\n",
    "    image = preprocess(raw_image)\n",
    "    image = random_transform(image)\n",
    "#     del raw_image\n",
    "    return image\n",
    "\n",
    "def file_list_to_image_array(file_list):\n",
    "    return np.stack([file_to_image(f) for f in file_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = data['Image']\n",
    "y = data['Id']\n",
    "\n",
    "#Use this to test simple classification\n",
    "# y = y.map(lambda x: int(x=='new_whale'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "files_train, files_test, y_train, y_test = train_test_split(\n",
    "    files, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(iterable, batch_size=1):\n",
    "    while True:\n",
    "        l = len(iterable)\n",
    "        for ndx in range(0, l, batch_size):\n",
    "            yield iterable[ndx:min(ndx + batch_size, l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now need to create the pairs of images inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_same_whale_image(x):\n",
    "    filtered = data[(data['Id'] == x['Id'])]\n",
    "    return filtered.sample(1).values[0] \n",
    "\n",
    "def get_different_whale_image(x):\n",
    "    filtered = data[(data['Id'] != x['Id'])]\n",
    "    return filtered.sample(1).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BINARY_DATASET_SIZE = 10000\n",
    "\n",
    "SAME_WHALE_DATASET_SIZE = BINARY_DATASET_SIZE // 2\n",
    "DIFFERENT_WHALE_DATASET_SIZE = BINARY_DATASET_SIZE // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "same_whale_dataset = data.sample(SAME_WHALE_DATASET_SIZE, replace=True)\n",
    "same_whale_dataset[['Image2', 'Id2']] = same_whale_dataset.apply(get_same_whale_image, axis=1)\n",
    "same_whale_dataset.columns = ['Image1', 'Id1','Image2', 'Id2']\n",
    "same_whale_dataset = same_whale_dataset[same_whale_dataset['Image1'] != same_whale_dataset['Image2']]\n",
    "same_whale_dataset['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "different_whale_dataset = data.sample(DIFFERENT_WHALE_DATASET_SIZE, replace=True)\n",
    "different_whale_dataset[['Image2', 'Id2']] = different_whale_dataset.apply(get_different_whale_image, axis=1)\n",
    "different_whale_dataset.columns = ['Image1', 'Id1','Image2', 'Id2']\n",
    "different_whale_dataset['target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_dataset = pd.concat([same_whale_dataset, different_whale_dataset]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7649"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(binary_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_data_generator(batch_size):\n",
    "    file_1_generator = batch_generator(binary_dataset['Image1'], batch_size)\n",
    "    file_2_generator = batch_generator(binary_dataset['Image2'], batch_size)\n",
    "    target_generator = batch_generator(binary_dataset['target'], batch_size)\n",
    "    \n",
    "    while True:\n",
    "        file_1_batch = next(file_1_generator)\n",
    "        file_2_batch = next(file_2_generator)\n",
    "        \n",
    "        image_1_batch = file_list_to_image_array(file_1_batch)\n",
    "        image_2_batch = file_list_to_image_array(file_2_batch)\n",
    "        \n",
    "        pairs = [image_1_batch, image_2_batch]\n",
    "        targets = next(target_generator)\n",
    "        \n",
    "        yield pairs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "siamese_data_generator = binary_data_generator(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(siamese_data_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be the correct generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:22: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/opt/anaconda3/lib/python3.5/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/opt/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "input_shape = (256, 256)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "#build convnet to use in each siamese 'leg'\n",
    "\n",
    "convnet = Sequential()\n",
    "convnet.add(Reshape((256, 256, 1,), input_shape=(256,256,),name='Reshape'))\n",
    "convnet.add(Conv2D(filters=8, input_shape=(256,256,1,), kernel_size=3, activation='relu',name='conv_1'))\n",
    "convnet.add(MaxPooling2D(pool_size=2,name='pool_1'))\n",
    "convnet.add(Conv2D(filters=16, kernel_size=3, activation='relu',name='conv_2'))\n",
    "convnet.add(MaxPooling2D(pool_size=2,name='pool_2'))\n",
    "convnet.add(Conv2D(filters=32, kernel_size=3, activation='relu',name='conv_3'))\n",
    "convnet.add(MaxPooling2D(pool_size=2,name='pool_3'))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(units=1024, activation='relu',name='dense_1'))\n",
    "\n",
    "#encode each of the two inputs into a vector with the convnet\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "#merge two encoded inputs with the l1 distance between them\n",
    "L1_distance = lambda x: K.abs(x[0]-x[1])\n",
    "both = merge([encoded_l,encoded_r], mode = L1_distance, output_shape=lambda x: x[0])\n",
    "prediction = Dense(1,activation='sigmoid')(both)\n",
    "siamese_net = Model(input=[left_input,right_input],output=prediction)\n",
    "optimizer=Adam(0.00001)\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy:  0.6536802196365539\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline accuracy: \",1 - np.mean(binary_dataset['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "59/59 [==============================] - 503s 9s/step - loss: 1.5328 - acc: 0.5776\n",
      "Epoch 2/100\n",
      "59/59 [==============================] - 495s 8s/step - loss: 1.2157 - acc: 0.5964\n",
      "Epoch 3/100\n",
      "59/59 [==============================] - 494s 8s/step - loss: 1.1380 - acc: 0.6089\n",
      "Epoch 4/100\n",
      "58/59 [============================>.] - ETA: 8s - loss: 1.0181 - acc: 0.6149 "
     ]
    }
   ],
   "source": [
    "history = siamese_net.fit_generator(siamese_data_generator, verbose=1, epochs = 100, steps_per_epoch=len(binary_dataset)//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
