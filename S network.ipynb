{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data_augmentation import random_transform\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Reshape, Flatten, Input, merge, subtract\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resize_shape = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For now, we remove new_whale\n",
    "data = data[data['Id'] != 'new_whale'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9040"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open('data/train/0a5c0f48.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = image.resize(resize_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gray = np.mean(image, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.imshow(random_transform(gray),cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# All images (if small) can be held in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list = data['Image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image(file, shape=resize_shape):\n",
    "    image = Image.open('data/train/' + file)\n",
    "    image = image.resize(shape)\n",
    "    image = np.array(image)\n",
    "    if len(image.shape) == 3:\n",
    "        image = np.mean(image, -1) \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_list = [get_image(f) for f in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['image_array'] = image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "      <th>image_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00022e1a.jpg</td>\n",
       "      <td>w_e15442c</td>\n",
       "      <td>[[218, 220, 224, 231, 225, 246, 250, 241, 222,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000466c4.jpg</td>\n",
       "      <td>w_1287fbc</td>\n",
       "      <td>[[187.333333333, 191.333333333, 191.333333333,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00087b01.jpg</td>\n",
       "      <td>w_da2efe0</td>\n",
       "      <td>[[205.0, 183.0, 214.0, 199.0, 212.0, 215.0, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001296d5.jpg</td>\n",
       "      <td>w_19e5482</td>\n",
       "      <td>[[159.333333333, 164.333333333, 157.333333333,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image         Id                                        image_array\n",
       "0  00022e1a.jpg  w_e15442c  [[218, 220, 224, 231, 225, 246, 250, 241, 222,...\n",
       "1  000466c4.jpg  w_1287fbc  [[187.333333333, 191.333333333, 191.333333333,...\n",
       "2  00087b01.jpg  w_da2efe0  [[205.0, 183.0, 214.0, 199.0, 212.0, 215.0, 21...\n",
       "3  001296d5.jpg  w_19e5482  [[159.333333333, 164.333333333, 157.333333333,..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data = shuffle(data)\n",
    "\n",
    "test_proportion = 0.8\n",
    "cutoff_index = int(len(data) * test_proportion)\n",
    "\n",
    "training_data = data.iloc[:cutoff_index].reset_index(drop=True)\n",
    "test_data = data.iloc[cutoff_index:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "training_counts = Counter(training_data['Id'])\n",
    "training_data['Id_count'] = training_data.apply(lambda x: training_counts.get(x[\"Id\"]), axis=1)\n",
    "\n",
    "test_counts = Counter(test_data['Id'])\n",
    "test_data['Id_count'] = test_data.apply(lambda x: test_counts.get(x[\"Id\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_different_category_example(data):\n",
    "    index_1 = randint(0,len(data)-1)\n",
    "    image_1 = data['image_array'][index_1]\n",
    "    id_1 = data['Id'][index_1]\n",
    "    id_2 = id_1\n",
    "    while (id_1 == id_2):\n",
    "        index_2 = randint(0,len(data)-1)\n",
    "        id_2 = data['Id'][index_2]\n",
    "    \n",
    "    image_2 = data['image_array'][index_2]\n",
    "    \n",
    "    image_1 = random_transform(image_1)\n",
    "    image_2 = random_transform(image_2)\n",
    "    return image_1, image_2\n",
    "\n",
    "def get_same_category_example(data):\n",
    "    filtered = data[data['Id_count'] > 1].reset_index(drop=True)\n",
    "    index_1 = randint(0,len(filtered)-1)\n",
    "    image_1 = filtered['image_array'][index_1]\n",
    "    id_1 = filtered['Id'][index_1]   \n",
    "    id_2 = id_1\n",
    "    relevant_indices = list(filtered.index[filtered['Id'] == id_1])\n",
    "#     relevant_indices.remove(index_1)\n",
    "    index_2 = np.random.choice(relevant_indices)\n",
    "    image_2 = filtered['image_array'][index_2]\n",
    "    \n",
    "    image_1 = random_transform(image_1)\n",
    "    image_2 = random_transform(image_2)\n",
    "    return image_1, image_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_data_generator(batch_size, data, resize_shape, p=0.5):\n",
    "    while True:\n",
    "        targets = np.random.randint(2, size=batch_size)\n",
    "        image_1_batch = np.zeros((batch_size, resize_shape[0],resize_shape[1]))\n",
    "        image_2_batch = np.zeros((batch_size, resize_shape[0],resize_shape[1]))\n",
    "        for i in range(batch_size):\n",
    "            if(targets[i]):\n",
    "                image_1_batch[i,:,:], image_2_batch[i,:,:] = get_same_category_example(data)\n",
    "            else:\n",
    "                image_1_batch[i,:,:], image_2_batch[i,:,:] = get_different_category_example(data)\n",
    "\n",
    "        pairs = [image_1_batch, image_2_batch]\n",
    "\n",
    "        yield pairs, targets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L2_distance(X):\n",
    "\n",
    "    encoded_l, encoded_r = X\n",
    "\n",
    "    # BPR loss\n",
    "    loss = 1.0 - K.sigmoid(\n",
    "        K.sum(user_latent * positive_item_latent, axis=-1, keepdims=True) -\n",
    "        K.sum(user_latent * negative_item_latent, axis=-1, keepdims=True))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:19: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/opt/anaconda3/lib/python3.5/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/opt/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "input_shape = resize_shape\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "\n",
    "convnet = Sequential()\n",
    "convnet.add(Reshape((resize_shape[0],resize_shape[1], 1,), input_shape=(resize_shape[0],resize_shape[1],),name='Reshape'))\n",
    "convnet.add(Conv2D(filters=2, input_shape=(resize_shape[0],resize_shape[1],1,), kernel_size=5, activation='relu',name='conv_1'))\n",
    "convnet.add(Conv2D(filters=4, kernel_size=5, activation='relu',name='conv_2'))\n",
    "convnet.add(MaxPooling2D(pool_size=2,name='pool_1'))\n",
    "convnet.add(Conv2D(filters=8, kernel_size=3, activation='relu',name='conv_3'))\n",
    "convnet.add(Conv2D(filters=12, kernel_size=3, activation='relu',name='conv_4'))\n",
    "convnet.add(MaxPooling2D(pool_size=2,name='pool_2'))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(units=32, activation='relu',name='dense_1'))\n",
    "\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "L1_distance = lambda x: K.abs(x[0]-x[1])\n",
    "both = merge([encoded_l,encoded_r], mode = L1_distance, output_shape=lambda x: x[0])\n",
    "prediction = Dense(1,activation='sigmoid')(both)\n",
    "siamese_net = Model(input=[left_input,right_input],output=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.00001\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "training_data_generator = binary_data_generator(BATCH_SIZE, training_data, resize_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.7968 - acc: 0.5837\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 18s 175ms/step - loss: 0.6651 - acc: 0.6019\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 17s 175ms/step - loss: 0.6497 - acc: 0.6312\n",
      "Epoch 4/10\n",
      " 48/100 [=============>................] - ETA: 9s - loss: 0.6521 - acc: 0.6510"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-250f7106e542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiamese_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2081\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2083\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = siamese_net.fit_generator(training_data_generator, verbose=1, epochs=10, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.644228013754\n",
      "acc: 0.646875\n"
     ]
    }
   ],
   "source": [
    "evaluation_data_generator = binary_data_generator(BATCH_SIZE, test_data, resize_shape)\n",
    "\n",
    "evaluation_steps = 100\n",
    "metric_names = siamese_net.metrics_names\n",
    "metric_values = siamese_net.evaluate_generator(evaluation_data_generator, steps=evaluation_steps)\n",
    "for i in range(len(siamese_net.metrics_names)):\n",
    "    print(metric_names[i], \": \", metric_values[i], sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "now = time.strftime('%Y.%m.%d %H:%M:%S')\n",
    "directory = \"weights/\" + now + \"/\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "\n",
    "siamese_net.save_weights(directory + \"siamese_weights\")\n",
    "convnet.save_weights(directory + \"convnet_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_category(image, model, training_images, training_categories):\n",
    "    training_stack = np.stack(training_images)\n",
    "    input_stack = np.repeat(image, len(training_stack), axis=0)\n",
    "    binary_predictions = model.predict([training_stack,input_stack])\n",
    "    binary_predictions = [x[0] for x in binary_predictions]\n",
    "    \n",
    "    predicted_index = np.argmax(binary_predictions)\n",
    "    return training_categories[predicted_index]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52301055"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Same image should return 1. Investigate this?\n",
    "#No because sigmoid of 0 is 0.5. Still seems not ideal.\n",
    "# Probably this would be improved by freezing the features weights.\n",
    "\n",
    "\n",
    "image_1 = training_data['image_array'][0]\n",
    "image_1 = np.expand_dims(image_1,0)\n",
    "image_2 = training_data['image_array'][0]\n",
    "image_2 = np.expand_dims(image_2,0)\n",
    "\n",
    "siamese_net.predict([image_1,image_2])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "      <th>image_array</th>\n",
       "      <th>Id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3ce58221.jpg</td>\n",
       "      <td>w_0626e4d</td>\n",
       "      <td>[[206.666666667, 211.333333333, 204.666666667,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a3844c28.jpg</td>\n",
       "      <td>w_77ee0be</td>\n",
       "      <td>[[217.0, 214.0, 181.0, 170.0, 199.0, 217.0, 17...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6530809b.jpg</td>\n",
       "      <td>w_ba53619</td>\n",
       "      <td>[[160.666666667, 160.666666667, 160.666666667,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94e800b6.jpg</td>\n",
       "      <td>w_1609b19</td>\n",
       "      <td>[[221.0, 205.0, 202.0, 196.0, 211.0, 211.0, 19...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image         Id                                        image_array  \\\n",
       "0  3ce58221.jpg  w_0626e4d  [[206.666666667, 211.333333333, 204.666666667,...   \n",
       "1  a3844c28.jpg  w_77ee0be  [[217.0, 214.0, 181.0, 170.0, 199.0, 217.0, 17...   \n",
       "2  6530809b.jpg  w_ba53619  [[160.666666667, 160.666666667, 160.666666667,...   \n",
       "3  94e800b6.jpg  w_1609b19  [[221.0, 205.0, 202.0, 196.0, 211.0, 211.0, 19...   \n",
       "\n",
       "   Id_count  \n",
       "0         2  \n",
       "1         2  \n",
       "2         3  \n",
       "3         2  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_1 = training_data['image_array'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w_3a47dba'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_category(image_1, siamese_net, training_data['image_array'], training_data['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
